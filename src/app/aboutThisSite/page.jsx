import styles from './aboutthissite.module.css';

const AboutThisSite = () => {
    return (
        <div className={styles.container}>
            <h1 className={styles.title}>About This Site</h1>

            <section className={styles.section}>
                <h2 className={styles.sectionTitle}>Frontend</h2>
                <p className={styles.text}>
                    This website is built using <strong>Next.js</strong>. It is ideal for a portfolio site due to its performance and SEO benefits.
                </p>
            </section>

            <section className={styles.section}>
                <h2 className={styles.sectionTitle}>Backend</h2>
                <p className={styles.text}>
                    The backend is powered by an AI-driven architecture. The &quot;Chat With AI Me&quot; feature uses <strong>LangChain</strong> for managing conversations and integrations. The LLM I choose is <strong>GPT-4o-mini</strong>, a model optimized for cost-efficient and accurate large language model interactions.
                </p>
                <p className={styles.text}>
                    My personal information is vectorized and stored in <strong>Pinecone</strong> for real-time retrieval. I use <strong>RAG</strong> to fetch relevant data from Pinecone, enhancing responses generated by <strong>GPT-4o-mini</strong> for accurate and relevant AI interactions.
                </p>
                <p className={styles.text}>
                    The backend is packaged as a <strong>Docker image</strong> and deployed via <strong>AWS Lambda</strong>. The API is exposed through Lambda&apos;s <strong>Function URL</strong>, ensuring efficient scaling and cost optimization while maintaining simplicity in the architecture.
                </p>
            </section>

            <section className={styles.section}>
                <h2 className={styles.sectionTitle}>Deployment</h2>
                <p className={styles.text}>
                    The frontend is automatically deployed via <strong>AWS Amplify</strong> using its built-in CI/CD features. </p>
                <p className={styles.text}>
                    The backend CI/CD is managed with <strong>AWS CodePipeline</strong>, written using <strong>AWS CDK Python</strong>, and includes resources like <strong>Lambda</strong>, <strong>Docker Image</strong>, and <strong>Function URL</strong> for automated deployment.
                </p>
            </section>

            <section className={styles.section}>
                <h2 className={styles.sectionTitle}>Trade-offs and Considerations</h2>
                <p className={styles.text}>
                    Although running Docker images inside AWS Lambda increases the cold start time, this architecture was chosen to maintain a consistent environment. The decision to skip API Gateway helps reduce the complexity and costs for this lightweight API. Additionally, the use of RAG improves AI interactions by ensuring that only the most relevant and personalized information is retrieved from Pinecone, thus balancing the trade-offs between cost and performance.
                </p>
            </section>
        </div>
    );
};

export default AboutThisSite;
